{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hvMUhvdusGBc"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
        "\n",
        "import shutil\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "\n",
        "from pathlib import Path\n",
        "from IPython.display import display, Audio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AKr0ireNsTpc"
      },
      "outputs": [],
      "source": [
        "DATASET_ROOT = \"SE_Project_Data\"\n",
        "\n",
        "# The folders in which we will put the audio samples and the noise samples\n",
        "AUDIO_SUBFOLDER = \"audio\"\n",
        "NOISE_SUBFOLDER = \"noise\"\n",
        "\n",
        "DATASET_AUDIO_PATH = os.path.join(DATASET_ROOT, AUDIO_SUBFOLDER)\n",
        "DATASET_NOISE_PATH = os.path.join(DATASET_ROOT, NOISE_SUBFOLDER)\n",
        "\n",
        "# Percentage of samples to use for validation\n",
        "VALID_SPLIT = 0.1\n",
        "\n",
        "# Seed to use when shuffling the dataset and the noise\n",
        "SHUFFLE_SEED = 43\n",
        "\n",
        "# The sampling rate to use.\n",
        "# This is the one used in all the audio samples.\n",
        "# We will resample all the noise to this sampling rate.\n",
        "# This will also be the output size of the audio wave samples\n",
        "# (since all samples are of 1 second long)\n",
        "SAMPLING_RATE = 16000\n",
        "\n",
        "# The factor to multiply the noise with according to:\n",
        "#   noisy_sample = sample + noise * prop * scale\n",
        "#      where prop = sample_amplitude / noise_amplitude\n",
        "SCALE = 0.5\n",
        "\n",
        "BATCH_SIZE = 128\n",
        "EPOCHS = 100\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NaQHjQIjsU5O"
      },
      "outputs": [],
      "source": [
        "for folder in os.listdir(DATASET_ROOT):\n",
        "    if os.path.isdir(os.path.join(DATASET_ROOT, folder)):\n",
        "        if folder in [AUDIO_SUBFOLDER, NOISE_SUBFOLDER]:\n",
        "            # If folder is `audio` or `noise`, do nothing\n",
        "            continue\n",
        "        elif folder in [\"other\", \"_background_noise_\"]:\n",
        "            # If folder is one of the folders that contains noise samples,\n",
        "            # move it to the `noise` folder\n",
        "            shutil.move(\n",
        "                os.path.join(DATASET_ROOT, folder),\n",
        "                os.path.join(DATASET_NOISE_PATH, folder),\n",
        "            )\n",
        "        else:\n",
        "            # Otherwise, it should be a speaker folder, then move it to\n",
        "            # `audio` folder\n",
        "            shutil.move(\n",
        "                os.path.join(DATASET_ROOT, folder),\n",
        "                os.path.join(DATASET_AUDIO_PATH, folder),\n",
        "            )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zEFZC_nzsWJi"
      },
      "outputs": [],
      "source": [
        "voicefile_names = os.listdir(\"SE_Project_Data/audio\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RxuB8ZO8sXNI",
        "outputId": "29d2674c-4bad-49dd-cc06-1d706e65bbc6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['shees', 'ahad', 'shayan']"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "voicefile_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wTOPAQ7asYg_"
      },
      "outputs": [],
      "source": [
        "voice_files_count = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UGSbvg0ssZqi"
      },
      "outputs": [],
      "source": [
        "for t in voicefile_names:\n",
        "  p = os.listdir(\"SE_Project_Data/audio\"+\"/\"+t)\n",
        "  len_class=len(p)\n",
        "  voice_files_count.append(len_class)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2zXWdggsbaN",
        "outputId": "173f40ee-3882-4de7-da5d-cdca2bacaca7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[88, 88, 88]"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "voice_files_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "hMnxWXgTsdJL",
        "outputId": "70cca46c-b8d5-49c0-82f9-1f9e90bd4971"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.24.1.min.js\"></script>                <div id=\"53c71f11-cb56-47f1-a2f5-b10ed150ddeb\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"53c71f11-cb56-47f1-a2f5-b10ed150ddeb\")) {                    Plotly.newPlot(                        \"53c71f11-cb56-47f1-a2f5-b10ed150ddeb\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"index=%{x}\\u003cbr\\u003ey=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\",\"pattern\":{\"shape\":\"\"}},\"name\":\"\",\"offsetgroup\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"textposition\":\"auto\",\"x\":[0,1,2],\"xaxis\":\"x\",\"y\":[88,88,88],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"index\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"y\"}},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60},\"barmode\":\"relative\"},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('53c71f11-cb56-47f1-a2f5-b10ed150ddeb');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import plotly.express as px\n",
        "import numpy\n",
        "\n",
        "random_x = voicefile_names\n",
        "random_y = voice_files_count\n",
        "\n",
        "fig = px.bar(random_x, y = random_y)\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yhJGmmNHvgGl",
        "outputId": "3c482e76-9c46-4118-ae4c-b06f1c1d1e75"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 6 files belonging to 2 directories\n"
          ]
        }
      ],
      "source": [
        "# Get the list of all noise files\n",
        "noise_paths = []\n",
        "for subdir in os.listdir(DATASET_NOISE_PATH):\n",
        "    subdir_path = Path(DATASET_NOISE_PATH) / subdir\n",
        "    if os.path.isdir(subdir_path):\n",
        "        noise_paths += [\n",
        "            os.path.join(subdir_path, filepath)\n",
        "            for filepath in os.listdir(subdir_path)\n",
        "            if filepath.endswith(\".wav\")\n",
        "        ]\n",
        "if not noise_paths:\n",
        "    raise RuntimeError(f\"Could not find any files at {DATASET_NOISE_PATH}\")\n",
        "print(\n",
        "    \"Found {} files belonging to {} directories\".format(\n",
        "        len(noise_paths), len(os.listdir(DATASET_NOISE_PATH))\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-xNtQi4MvhkB",
        "outputId": "57e8f93d-94cc-482e-c747-976c0f0e0b0b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6 noise files were split into 354 noise samples where each is 1 sec. long\n"
          ]
        }
      ],
      "source": [
        "command = (\n",
        "    \"for dir in `ls -1 \" + DATASET_NOISE_PATH + \"`; do \"\n",
        "    \"for file in `ls -1 \" + DATASET_NOISE_PATH + \"/$dir/*.wav`; do \"\n",
        "    \"sample_rate=`ffprobe -hide_banner -loglevel panic -show_streams \"\n",
        "    \"$file | grep sample_rate | cut -f2 -d=`; \"\n",
        "    \"if [ $sample_rate -ne 16000 ]; then \"\n",
        "    \"ffmpeg -hide_banner -loglevel panic -y \"\n",
        "    \"-i $file -ar 16000 temp.wav; \"\n",
        "    \"mv temp.wav $file; \"\n",
        "    \"fi; done; done\"\n",
        ")\n",
        "os.system(command)\n",
        "\n",
        "\n",
        "# Split noise into chunks of 16,000 steps each\n",
        "def load_noise_sample(path):\n",
        "    sample, sampling_rate = tf.audio.decode_wav(\n",
        "        tf.io.read_file(path), desired_channels=1\n",
        "    )\n",
        "    if sampling_rate == SAMPLING_RATE:\n",
        "        # Number of slices of 16000 each that can be generated from the noise sample\n",
        "        slices = int(sample.shape[0] / SAMPLING_RATE)\n",
        "        sample = tf.split(sample[: slices * SAMPLING_RATE], slices)\n",
        "        return sample\n",
        "    else:\n",
        "        print(\"Sampling rate for {} is incorrect. Ignoring it\".format(path))\n",
        "        return None\n",
        "\n",
        "\n",
        "noises = []\n",
        "for path in noise_paths:\n",
        "    sample = load_noise_sample(path)\n",
        "    if sample:\n",
        "        noises.extend(sample)\n",
        "noises = tf.stack(noises)\n",
        "\n",
        "print(\n",
        "    \"{} noise files were split into {} noise samples where each is {} sec. long\".format(\n",
        "        len(noise_paths), noises.shape[0], noises.shape[1] // SAMPLING_RATE\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jsbwlC6tvi2t",
        "outputId": "f5c897f2-afaa-4207-9ebf-083e5f0bbe9f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Our class names: ['shees', 'ahad', 'shayan']\n",
            "Processing speaker shees\n",
            "Processing speaker ahad\n",
            "Processing speaker shayan\n",
            "Found 264 files belonging to 3 classes.\n",
            "Using 238 files for training.\n",
            "Using 26 files for validation.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def paths_and_labels_to_dataset(audio_paths, labels):\n",
        "    \"\"\"Constructs a dataset of audios and labels.\"\"\"\n",
        "    path_ds = tf.data.Dataset.from_tensor_slices(audio_paths)\n",
        "    audio_ds = path_ds.map(\n",
        "        lambda x: path_to_audio(x), num_parallel_calls=tf.data.AUTOTUNE\n",
        "    )\n",
        "    label_ds = tf.data.Dataset.from_tensor_slices(labels)\n",
        "    return tf.data.Dataset.zip((audio_ds, label_ds))\n",
        "\n",
        "\n",
        "def path_to_audio(path):\n",
        "    \"\"\"Reads and decodes an audio file.\"\"\"\n",
        "    audio = tf.io.read_file(path)\n",
        "    audio, _ = tf.audio.decode_wav(audio, 1, SAMPLING_RATE)\n",
        "    return audio\n",
        "\n",
        "\n",
        "def add_noise(audio, noises=None, scale=0.5):\n",
        "    if noises is not None:\n",
        "        # Create a random tensor of the same size as audio ranging from\n",
        "        # 0 to the number of noise stream samples that we have.\n",
        "        tf_rnd = tf.random.uniform(\n",
        "            (tf.shape(audio)[0],), 0, noises.shape[0], dtype=tf.int32\n",
        "        )\n",
        "        noise = tf.gather(noises, tf_rnd, axis=0)\n",
        "\n",
        "        # Get the amplitude proportion between the audio and the noise\n",
        "        prop = tf.math.reduce_max(audio, axis=1) / tf.math.reduce_max(noise, axis=1)\n",
        "        prop = tf.repeat(tf.expand_dims(prop, axis=1), tf.shape(audio)[1], axis=1)\n",
        "\n",
        "        # Adding the rescaled noise to audio\n",
        "        audio = audio + noise * prop * scale\n",
        "\n",
        "    return audio\n",
        "\n",
        "\n",
        "def audio_to_fft(audio):\n",
        "    # Since tf.signal.fft applies FFT on the innermost dimension,\n",
        "    # we need to squeeze the dimensions and then expand them again\n",
        "    # after FFT\n",
        "    audio = tf.squeeze(audio, axis=-1)\n",
        "    fft = tf.signal.fft(\n",
        "        tf.cast(tf.complex(real=audio, imag=tf.zeros_like(audio)), tf.complex64)\n",
        "    )\n",
        "    fft = tf.expand_dims(fft, axis=-1)\n",
        "\n",
        "    # Return the absolute value of the first half of the FFT\n",
        "    # which represents the positive frequencies\n",
        "    return tf.math.abs(fft[:, : (audio.shape[1] // 2), :])\n",
        "\n",
        "\n",
        "# Get the list of audio file paths along with their corresponding labels\n",
        "\n",
        "class_names = os.listdir(DATASET_AUDIO_PATH)\n",
        "print(\n",
        "    \"Our class names: {}\".format(\n",
        "        class_names,\n",
        "    )\n",
        ")\n",
        "\n",
        "audio_paths = []\n",
        "labels = []\n",
        "for label, name in enumerate(class_names):\n",
        "    print(\n",
        "        \"Processing speaker {}\".format(\n",
        "            name,\n",
        "        )\n",
        "    )\n",
        "    dir_path = Path(DATASET_AUDIO_PATH) / name\n",
        "    speaker_sample_paths = [\n",
        "        os.path.join(dir_path, filepath)\n",
        "        for filepath in os.listdir(dir_path)\n",
        "        if filepath.endswith(\".wav\")\n",
        "    ]\n",
        "    audio_paths += speaker_sample_paths\n",
        "    labels += [label] * len(speaker_sample_paths)\n",
        "\n",
        "print(\n",
        "    \"Found {} files belonging to {} classes.\".format(len(audio_paths), len(class_names))\n",
        ")\n",
        "\n",
        "# Shuffle\n",
        "rng = np.random.RandomState(SHUFFLE_SEED)\n",
        "rng.shuffle(audio_paths)\n",
        "rng = np.random.RandomState(SHUFFLE_SEED)\n",
        "rng.shuffle(labels)\n",
        "\n",
        "# Split into training and validation\n",
        "num_val_samples = int(VALID_SPLIT * len(audio_paths))\n",
        "print(\"Using {} files for training.\".format(len(audio_paths) - num_val_samples))\n",
        "train_audio_paths = audio_paths[:-num_val_samples]\n",
        "train_labels = labels[:-num_val_samples]\n",
        "\n",
        "print(\"Using {} files for validation.\".format(num_val_samples))\n",
        "valid_audio_paths = audio_paths[-num_val_samples:]\n",
        "valid_labels = labels[-num_val_samples:]\n",
        "\n",
        "# Create 2 datasets, one for training and the other for validation\n",
        "train_ds = paths_and_labels_to_dataset(train_audio_paths, train_labels)\n",
        "train_ds = train_ds.shuffle(buffer_size=BATCH_SIZE * 8, seed=SHUFFLE_SEED).batch(\n",
        "    BATCH_SIZE\n",
        ")\n",
        "\n",
        "valid_ds = paths_and_labels_to_dataset(valid_audio_paths, valid_labels)\n",
        "valid_ds = valid_ds.shuffle(buffer_size=32 * 8, seed=SHUFFLE_SEED).batch(32)\n",
        "\n",
        "\n",
        "# Add noise to the training set\n",
        "train_ds = train_ds.map(\n",
        "    lambda x, y: (add_noise(x, noises, scale=SCALE), y),\n",
        "    num_parallel_calls=tf.data.AUTOTUNE,\n",
        ")\n",
        "\n",
        "# Transform audio wave to the frequency domain using `audio_to_fft`\n",
        "train_ds = train_ds.map(\n",
        "    lambda x, y: (audio_to_fft(x), y), num_parallel_calls=tf.data.AUTOTUNE\n",
        ")\n",
        "train_ds = train_ds.prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "valid_ds = valid_ds.map(\n",
        "    lambda x, y: (audio_to_fft(x), y), num_parallel_calls=tf.data.AUTOTUNE\n",
        ")\n",
        "valid_ds = valid_ds.prefetch(tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4A39ej_MvkOJ",
        "outputId": "7865a6c8-69d6-4a2a-89a3-673a6b4f029d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input (InputLayer)          [(None, 8000, 1)]            0         []                            \n",
            "                                                                                                  \n",
            " conv1d_1 (Conv1D)           (None, 8000, 16)             64        ['input[0][0]']               \n",
            "                                                                                                  \n",
            " activation (Activation)     (None, 8000, 16)             0         ['conv1d_1[0][0]']            \n",
            "                                                                                                  \n",
            " conv1d_2 (Conv1D)           (None, 8000, 16)             784       ['activation[0][0]']          \n",
            "                                                                                                  \n",
            " conv1d (Conv1D)             (None, 8000, 16)             32        ['input[0][0]']               \n",
            "                                                                                                  \n",
            " add (Add)                   (None, 8000, 16)             0         ['conv1d_2[0][0]',            \n",
            "                                                                     'conv1d[0][0]']              \n",
            "                                                                                                  \n",
            " activation_1 (Activation)   (None, 8000, 16)             0         ['add[0][0]']                 \n",
            "                                                                                                  \n",
            " max_pooling1d (MaxPooling1  (None, 4000, 16)             0         ['activation_1[0][0]']        \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv1d_4 (Conv1D)           (None, 4000, 32)             1568      ['max_pooling1d[0][0]']       \n",
            "                                                                                                  \n",
            " activation_2 (Activation)   (None, 4000, 32)             0         ['conv1d_4[0][0]']            \n",
            "                                                                                                  \n",
            " conv1d_5 (Conv1D)           (None, 4000, 32)             3104      ['activation_2[0][0]']        \n",
            "                                                                                                  \n",
            " conv1d_3 (Conv1D)           (None, 4000, 32)             544       ['max_pooling1d[0][0]']       \n",
            "                                                                                                  \n",
            " add_1 (Add)                 (None, 4000, 32)             0         ['conv1d_5[0][0]',            \n",
            "                                                                     'conv1d_3[0][0]']            \n",
            "                                                                                                  \n",
            " activation_3 (Activation)   (None, 4000, 32)             0         ['add_1[0][0]']               \n",
            "                                                                                                  \n",
            " max_pooling1d_1 (MaxPoolin  (None, 2000, 32)             0         ['activation_3[0][0]']        \n",
            " g1D)                                                                                             \n",
            "                                                                                                  \n",
            " conv1d_7 (Conv1D)           (None, 2000, 64)             6208      ['max_pooling1d_1[0][0]']     \n",
            "                                                                                                  \n",
            " activation_4 (Activation)   (None, 2000, 64)             0         ['conv1d_7[0][0]']            \n",
            "                                                                                                  \n",
            " conv1d_8 (Conv1D)           (None, 2000, 64)             12352     ['activation_4[0][0]']        \n",
            "                                                                                                  \n",
            " activation_5 (Activation)   (None, 2000, 64)             0         ['conv1d_8[0][0]']            \n",
            "                                                                                                  \n",
            " conv1d_9 (Conv1D)           (None, 2000, 64)             12352     ['activation_5[0][0]']        \n",
            "                                                                                                  \n",
            " conv1d_6 (Conv1D)           (None, 2000, 64)             2112      ['max_pooling1d_1[0][0]']     \n",
            "                                                                                                  \n",
            " add_2 (Add)                 (None, 2000, 64)             0         ['conv1d_9[0][0]',            \n",
            "                                                                     'conv1d_6[0][0]']            \n",
            "                                                                                                  \n",
            " activation_6 (Activation)   (None, 2000, 64)             0         ['add_2[0][0]']               \n",
            "                                                                                                  \n",
            " max_pooling1d_2 (MaxPoolin  (None, 1000, 64)             0         ['activation_6[0][0]']        \n",
            " g1D)                                                                                             \n",
            "                                                                                                  \n",
            " conv1d_11 (Conv1D)          (None, 1000, 128)            24704     ['max_pooling1d_2[0][0]']     \n",
            "                                                                                                  \n",
            " activation_7 (Activation)   (None, 1000, 128)            0         ['conv1d_11[0][0]']           \n",
            "                                                                                                  \n",
            " conv1d_12 (Conv1D)          (None, 1000, 128)            49280     ['activation_7[0][0]']        \n",
            "                                                                                                  \n",
            " activation_8 (Activation)   (None, 1000, 128)            0         ['conv1d_12[0][0]']           \n",
            "                                                                                                  \n",
            " conv1d_13 (Conv1D)          (None, 1000, 128)            49280     ['activation_8[0][0]']        \n",
            "                                                                                                  \n",
            " conv1d_10 (Conv1D)          (None, 1000, 128)            8320      ['max_pooling1d_2[0][0]']     \n",
            "                                                                                                  \n",
            " add_3 (Add)                 (None, 1000, 128)            0         ['conv1d_13[0][0]',           \n",
            "                                                                     'conv1d_10[0][0]']           \n",
            "                                                                                                  \n",
            " activation_9 (Activation)   (None, 1000, 128)            0         ['add_3[0][0]']               \n",
            "                                                                                                  \n",
            " max_pooling1d_3 (MaxPoolin  (None, 500, 128)             0         ['activation_9[0][0]']        \n",
            " g1D)                                                                                             \n",
            "                                                                                                  \n",
            " conv1d_15 (Conv1D)          (None, 500, 128)             49280     ['max_pooling1d_3[0][0]']     \n",
            "                                                                                                  \n",
            " activation_10 (Activation)  (None, 500, 128)             0         ['conv1d_15[0][0]']           \n",
            "                                                                                                  \n",
            " conv1d_16 (Conv1D)          (None, 500, 128)             49280     ['activation_10[0][0]']       \n",
            "                                                                                                  \n",
            " activation_11 (Activation)  (None, 500, 128)             0         ['conv1d_16[0][0]']           \n",
            "                                                                                                  \n",
            " conv1d_17 (Conv1D)          (None, 500, 128)             49280     ['activation_11[0][0]']       \n",
            "                                                                                                  \n",
            " conv1d_14 (Conv1D)          (None, 500, 128)             16512     ['max_pooling1d_3[0][0]']     \n",
            "                                                                                                  \n",
            " add_4 (Add)                 (None, 500, 128)             0         ['conv1d_17[0][0]',           \n",
            "                                                                     'conv1d_14[0][0]']           \n",
            "                                                                                                  \n",
            " activation_12 (Activation)  (None, 500, 128)             0         ['add_4[0][0]']               \n",
            "                                                                                                  \n",
            " max_pooling1d_4 (MaxPoolin  (None, 250, 128)             0         ['activation_12[0][0]']       \n",
            " g1D)                                                                                             \n",
            "                                                                                                  \n",
            " average_pooling1d (Average  (None, 83, 128)              0         ['max_pooling1d_4[0][0]']     \n",
            " Pooling1D)                                                                                       \n",
            "                                                                                                  \n",
            " flatten (Flatten)           (None, 10624)                0         ['average_pooling1d[0][0]']   \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, 256)                  2720000   ['flatten[0][0]']             \n",
            "                                                                                                  \n",
            " dense_1 (Dense)             (None, 128)                  32896     ['dense[0][0]']               \n",
            "                                                                                                  \n",
            " output (Dense)              (None, 3)                    387       ['dense_1[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 3088339 (11.78 MB)\n",
            "Trainable params: 3088339 (11.78 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def residual_block(x, filters, conv_num=3, activation=\"relu\"):\n",
        "    # Shortcut\n",
        "    s = keras.layers.Conv1D(filters, 1, padding=\"same\")(x)\n",
        "    for i in range(conv_num - 1):\n",
        "        x = keras.layers.Conv1D(filters, 3, padding=\"same\")(x)\n",
        "        x = keras.layers.Activation(activation)(x)\n",
        "    x = keras.layers.Conv1D(filters, 3, padding=\"same\")(x)\n",
        "    x = keras.layers.Add()([x, s])\n",
        "    x = keras.layers.Activation(activation)(x)\n",
        "    return keras.layers.MaxPool1D(pool_size=2, strides=2)(x)\n",
        "\n",
        "\n",
        "def build_model(input_shape, num_classes):\n",
        "    inputs = keras.layers.Input(shape=input_shape, name=\"input\")\n",
        "\n",
        "    x = residual_block(inputs, 16, 2)\n",
        "    x = residual_block(x, 32, 2)\n",
        "    x = residual_block(x, 64, 3)\n",
        "    x = residual_block(x, 128, 3)\n",
        "    x = residual_block(x, 128, 3)\n",
        "\n",
        "    x = keras.layers.AveragePooling1D(pool_size=3, strides=3)(x)\n",
        "    x = keras.layers.Flatten()(x)\n",
        "    x = keras.layers.Dense(256, activation=\"relu\")(x)\n",
        "    x = keras.layers.Dense(128, activation=\"relu\")(x)\n",
        "\n",
        "    outputs = keras.layers.Dense(num_classes, activation=\"softmax\", name=\"output\")(x)\n",
        "\n",
        "    return keras.models.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "\n",
        "model = build_model((SAMPLING_RATE // 2, 1), len(class_names))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# Compile the model using Adam's default learning rate\n",
        "model.compile(\n",
        "    optimizer=\"Adam\",\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "\n",
        "# Add callbacks:\n",
        "# 'EarlyStopping' to stop training when the model is not enhancing anymore\n",
        "# 'ModelCheckPoint' to always keep the model that has the best val_accuracy\n",
        "model_save_filename = \"model.keras\"\n",
        "\n",
        "earlystopping_cb = keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
        "mdlcheckpoint_cb = keras.callbacks.ModelCheckpoint(\n",
        "    model_save_filename, monitor=\"val_accuracy\", save_best_only=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cz3lDfM0vm26",
        "outputId": "8e617523-bb65-42af-dd30-c6da510da19d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2/2 [==============================] - 30s 9s/step - loss: 1.1238 - accuracy: 0.2521 - val_loss: 0.8890 - val_accuracy: 0.5769\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(\n",
        "    train_ds,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=valid_ds,\n",
        "    callbacks=[earlystopping_cb, mdlcheckpoint_cb],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kdzRH5mPvoBo",
        "outputId": "a03855df-bb19-47fd-8f10-55bf8c43b1c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 1s 516ms/step - loss: 0.8890 - accuracy: 0.5769\n",
            "[0.8890172243118286, 0.5769230723381042]\n"
          ]
        }
      ],
      "source": [
        "print(model.evaluate(valid_ds))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VkfIHYpK2Cna",
        "outputId": "c11e7ceb-3ce9-49e5-9e13-14877361f083"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting sounddevice\n",
            "  Downloading sounddevice-0.4.6-py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.10/dist-packages (from sounddevice) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from CFFI>=1.0->sounddevice) (2.22)\n",
            "Installing collected packages: sounddevice\n",
            "Successfully installed sounddevice-0.4.6\n"
          ]
        }
      ],
      "source": [
        "!pip install sounddevice"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lx6FaqHr2K9n",
        "outputId": "302621f1-3eb4-4189-980b-6c7e13f32997"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  libportaudio2\n",
            "0 upgraded, 1 newly installed, 0 to remove and 45 not upgraded.\n",
            "Need to get 65.3 kB of archives.\n",
            "After this operation, 223 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libportaudio2 amd64 19.6.0-1.1 [65.3 kB]\n",
            "Fetched 65.3 kB in 0s (397 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libportaudio2:amd64.\n",
            "(Reading database ... 121918 files and directories currently installed.)\n",
            "Preparing to unpack .../libportaudio2_19.6.0-1.1_amd64.deb ...\n",
            "Unpacking libportaudio2:amd64 (19.6.0-1.1) ...\n",
            "Setting up libportaudio2:amd64 (19.6.0-1.1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!sudo apt-get install libportaudio2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xe_G4xHn2buA",
        "outputId": "df10eb73-d9cf-4ade-e68a-34fdb842a8df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting ffmpeg-python\n",
            "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from ffmpeg-python) (0.18.3)\n",
            "Installing collected packages: ffmpeg-python\n",
            "Successfully installed ffmpeg-python-0.2.0\n"
          ]
        }
      ],
      "source": [
        "!pip install ffmpeg-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q5qEZxoJ2f_I"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "To write this piece of code I took inspiration/code from a lot of places.\n",
        "It was late night, so I'm not sure how much I created or just copied o.O\n",
        "Here are some of the possible references:\n",
        "https://blog.addpipe.com/recording-audio-in-the-browser-using-pure-html5-and-minimal-javascript/\n",
        "https://stackoverflow.com/a/18650249\n",
        "https://hacks.mozilla.org/2014/06/easy-audio-capture-with-the-mediarecorder-api/\n",
        "https://air.ghost.io/recording-to-an-audio-file-using-html5-and-js/\n",
        "https://stackoverflow.com/a/49019356\n",
        "\"\"\"\n",
        "from IPython.display import HTML, Audio\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "import numpy as np\n",
        "from scipy.io.wavfile import read as wav_read\n",
        "import io\n",
        "import ffmpeg\n",
        "\n",
        "AUDIO_HTML = \"\"\"\n",
        "<script>\n",
        "var my_div = document.createElement(\"DIV\");\n",
        "var my_p = document.createElement(\"P\");\n",
        "var my_btn = document.createElement(\"BUTTON\");\n",
        "var t = document.createTextNode(\"Press to start recording\");\n",
        "\n",
        "my_btn.appendChild(t);\n",
        "//my_p.appendChild(my_btn);\n",
        "my_div.appendChild(my_btn);\n",
        "document.body.appendChild(my_div);\n",
        "\n",
        "var base64data = 0;\n",
        "var reader;\n",
        "var recorder, gumStream;\n",
        "var recordButton = my_btn;\n",
        "\n",
        "var handleSuccess = function(stream) {\n",
        "  gumStream = stream;\n",
        "  var options = {\n",
        "    //bitsPerSecond: 8000, //chrome seems to ignore, always 48k\n",
        "    mimeType : 'audio/webm;codecs=opus'\n",
        "    //mimeType : 'audio/webm;codecs=pcm'\n",
        "  };\n",
        "  //recorder = new MediaRecorder(stream, options);\n",
        "  recorder = new MediaRecorder(stream);\n",
        "  recorder.ondataavailable = function(e) {\n",
        "    var url = URL.createObjectURL(e.data);\n",
        "    var preview = document.createElement('audio');\n",
        "    preview.controls = true;\n",
        "    preview.src = url;\n",
        "    document.body.appendChild(preview);\n",
        "\n",
        "    reader = new FileReader();\n",
        "    reader.readAsDataURL(e.data);\n",
        "    reader.onloadend = function() {\n",
        "      base64data = reader.result;\n",
        "      //console.log(\"Inside FileReader:\" + base64data);\n",
        "    }\n",
        "  };\n",
        "  recorder.start();\n",
        "  };\n",
        "\n",
        "recordButton.innerText = \"Recording... press to stop\";\n",
        "\n",
        "navigator.mediaDevices.getUserMedia({audio: true}).then(handleSuccess);\n",
        "\n",
        "\n",
        "function toggleRecording() {\n",
        "  if (recorder && recorder.state == \"recording\") {\n",
        "      recorder.stop();\n",
        "      gumStream.getAudioTracks()[0].stop();\n",
        "      recordButton.innerText = \"Saving the recording... pls wait!\"\n",
        "  }\n",
        "}\n",
        "\n",
        "// https://stackoverflow.com/a/951057\n",
        "function sleep(ms) {\n",
        "  return new Promise(resolve => setTimeout(resolve, ms));\n",
        "}\n",
        "\n",
        "var data = new Promise(resolve=>{\n",
        "//recordButton.addEventListener(\"click\", toggleRecording);\n",
        "recordButton.onclick = ()=>{\n",
        "toggleRecording()\n",
        "\n",
        "sleep(2000).then(() => {\n",
        "  // wait 2000ms for the data to be available...\n",
        "  // ideally this should use something like await...\n",
        "  //console.log(\"Inside data:\" + base64data)\n",
        "  resolve(base64data.toString())\n",
        "\n",
        "});\n",
        "\n",
        "}\n",
        "});\n",
        "\n",
        "</script>\n",
        "\"\"\"\n",
        "\n",
        "def get_audio():\n",
        "  display(HTML(AUDIO_HTML))\n",
        "  data = eval_js(\"data\")\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "\n",
        "  process = (ffmpeg\n",
        "    .input('pipe:0')\n",
        "    .output('pipe:1', format='wav')\n",
        "    .run_async(pipe_stdin=True, pipe_stdout=True, pipe_stderr=True, quiet=True, overwrite_output=True)\n",
        "  )\n",
        "  output, err = process.communicate(input=binary)\n",
        "\n",
        "  riff_chunk_size = len(output) - 8\n",
        "  # Break up the chunk size into four bytes, held in b.\n",
        "  q = riff_chunk_size\n",
        "  b = []\n",
        "  for i in range(4):\n",
        "      q, r = divmod(q, 256)\n",
        "      b.append(r)\n",
        "\n",
        "  # Replace bytes 4:8 in proc.stdout with the actual size of the RIFF chunk.\n",
        "  riff = output[:4] + bytes(b) + output[8:]\n",
        "\n",
        "  sr, audio = wav_read(io.BytesIO(riff))\n",
        "\n",
        "  return audio, sr"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SAMPLES_TO_DISPLAY = 10\n",
        "\n",
        "test_ds = paths_and_labels_to_dataset(valid_audio_paths, valid_labels)\n",
        "test_ds = test_ds.shuffle(buffer_size=BATCH_SIZE * 8, seed=SHUFFLE_SEED).batch(\n",
        "    BATCH_SIZE\n",
        ")\n",
        "\n",
        "test_ds = test_ds.map(\n",
        "    lambda x, y: (add_noise(x, noises, scale=SCALE), y),\n",
        "    num_parallel_calls=tf.data.AUTOTUNE,\n",
        ")\n",
        "\n",
        "for audios, labels in test_ds.take(1):\n",
        "    # Get the signal FFT\n",
        "    ffts = audio_to_fft(audios)\n",
        "    # Predict\n",
        "    y_pred = model.predict(ffts)\n",
        "    # Take random samples\n",
        "    rnd = np.random.randint(0, audios.shape[0], SAMPLES_TO_DISPLAY)  # Generate indices within the range of the number of samples\n",
        "    audios = audios.numpy()[rnd, :, :]\n",
        "    labels = labels.numpy()[rnd]\n",
        "    y_pred = np.argmax(y_pred, axis=-1)[rnd]\n",
        "\n",
        "    for index in range(SAMPLES_TO_DISPLAY):\n",
        "        # For every sample, print the true and predicted label\n",
        "        # as well as run the voice with the noise\n",
        "        print(\n",
        "            \"Speaker:\\33{} {}\\33[0m\\tPredicted:\\33{} {}\\33[0m\".format(\n",
        "                \"[92m\" if labels[index] == y_pred[index] else \"[91m\",\n",
        "                class_names[labels[index]],\n",
        "                \"[92m\" if labels[index] == y_pred[index] else \"[91m\",\n",
        "                class_names[y_pred[index]],\n",
        "            )\n",
        "        )\n",
        "\n",
        "        display(Audio(audios[index, :, :].squeeze(), rate=SAMPLING_RATE))"
      ],
      "metadata": {
        "id": "sf1EUC1O8PkM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def paths_to_dataset(audio_paths):\n",
        "  path_ds = tf.data.Dataset.from_tensor_slices(audio_paths)\n",
        "  return tf.data.Dataset.zip((path_ds))\n",
        "\n",
        "def predict(path, labels):\n",
        "  test = paths_and_labels_to_dataset(path, labels)\n",
        "\n",
        "\n",
        "  test = test.shuffle(BUFFER_SIZE=BATCH_SIZE * 8, seed=SHUFFLE_SEED).batch(\n",
        "      BATCH_SIZE\n",
        "  )\n",
        "  test = test.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "  test = test.map(lambda x, y: (add_noise(x, noises, scale = SCALE), y))\n",
        "\n",
        "  for audios, labels in test.take(1):\n",
        "    ffts = audio_to_fft(audios)\n",
        "    y_pred = model.predict(ffts)\n",
        "    rnd = np.random.randint(0, 1, 1)\n",
        "    audios = audios.numpy()[rnd, :]\n",
        "    labels = labels.numpy()[rnd]\n",
        "    y_pred = np.argmax(y_pred, axis=-1)[rnd]\n",
        "\n",
        "  for index in range(1):\n",
        "      print(\"Speaker:\\33[92m {}\\33[0m\\tPredicted:\\33[92m {}\\33[0m\".format(y_pred[index], y_pred[index]))\n",
        "      print(\"Speaker Predicted:\", class_names[y_pred[index]])"
      ],
      "metadata": {
        "id": "vKIp_KhH8WJk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "xDMNXCpVvrxd"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from scipy.io import wavfile\n",
        "from scipy.signal import resample\n",
        "from IPython.display import Audio, display\n",
        "import sounddevice as sd\n",
        "\n",
        "# Function to preprocess audio for prediction\n",
        "def preprocess_audio(audio, sampling_rate):\n",
        "    # Resample the audio to match the desired sampling rate\n",
        "    audio = resample(audio, int(len(audio) * (SAMPLING_RATE / sampling_rate)))\n",
        "    # Normalize the audio to [-1, 1]\n",
        "    audio = audio / np.max(np.abs(audio))\n",
        "    # Convert to spectrogram\n",
        "    fft = audio_to_fft(audio)\n",
        "    return fft\n",
        "\n",
        "# Function to predict the class of real-time audio\n",
        "def predict_realtime(model):\n",
        "    print(\"Speak Now...\")\n",
        "    audio, sr = get_audio()\n",
        "\n",
        "    print(\"Recording Complete!\")\n",
        "    # Preprocess the recorded audio\n",
        "    audio = preprocess_audio(audio[:, 0], SAMPLING_RATE)\n",
        "    # Reshape for prediction\n",
        "    audio = np.expand_dims(audio, axis=0)\n",
        "    # Predict\n",
        "    y_pred = np.argmax(model.predict(audio), axis=-1)\n",
        "    print(\"Predicted Speaker:\", class_names[y_pred[0]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "sCdDWPRevtVF"
      },
      "outputs": [],
      "source": [
        "def paths_to_dataset(audio_paths):\n",
        "    path_ds = tf.data.Dataset.from_tensor_slices(audio_paths)\n",
        "    return tf.data.Dataset.zip((path_ds))\n",
        "\n",
        "# Load the trained model\n",
        "model = tf.keras.models.load_model('model.keras')\n",
        "\n",
        "# Load the class names\n",
        "class_names = ['shees','shayan', 'ahad']  # Define your class names here\n",
        "\n",
        "# Function to predict from file paths (as in your original code)\n",
        "def predict_from_paths(paths, labels):\n",
        "    test_ds = paths_to_dataset(paths)\n",
        "    test_ds = test_ds.shuffle(buffer_size=BATCH_SIZE * 8, seed=SHUFFLE_SEED).batch(BATCH_SIZE)\n",
        "    test_ds = test_ds.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "    test_ds = test_ds.map(lambda x, y: (add_noise(x, noises, scale=SCALE), y))\n",
        "\n",
        "    for audios, labels in test_ds.take(1):\n",
        "        ffts = audio_to_fft(audios)\n",
        "        y_pred = model.predict(ffts)\n",
        "        rnd = np.random.randint(0, 1, 1)\n",
        "        audios = audios.numpy()[rnd, :]\n",
        "        labels = labels.numpy()[rnd]\n",
        "        y_pred = np.argmax(y_pred, axis=-1)[rnd]\n",
        "\n",
        "    for index in range(1):\n",
        "        print(\"Speaker:\\33[92m {}\\33[0m\\tPredicted:\\33[92m {}\\33[0m\".format(y_pred[index], y_pred[index]))\n",
        "        print(\"Speaker Predicted:\", class_names[y_pred[index]])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path = ['SE_Project_Data/audio/ahad/Abdul_Voice1.wav']\n",
        "labels = [\"unknown\"]\n",
        "\n",
        "try:\n",
        "  predict(path, labels)\n",
        "except:\n",
        "  print(\"Error! Check if the file correctly passed or not!\")"
      ],
      "metadata": {
        "id": "m76UjFmJ8dTL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WiqV0H3yvu1w",
        "outputId": "e39c17d8-ec40-4af3-8de4-69914008bc34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error! Check if the file correctly passed or not!\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    predict_realtime(model)\n",
        "except Exception as e:\n",
        "    print(\"Error:\", e)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}